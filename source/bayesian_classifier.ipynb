{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pre_processing(df: pd.DataFrame):\n",
    "    \"\"\"数据预处理\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): 原生数据集\n",
    "\n",
    "    Returns:\n",
    "        tuple: patterns_train, patterns_valid, classes_train, classes_valid\n",
    "    \"\"\"\n",
    "    # 类别编码\n",
    "    series = df[df.columns[-1]].value_counts()\n",
    "    dict = {series.index[i]: i for i in range(series.size)}\n",
    "    df[df.columns[-1]] = df[df.columns[-1]].map(dict)\n",
    "    # 划分数据集\n",
    "    patterns_train, patterns_valid, classes_train, classes_valid = train_test_split(\n",
    "        df.iloc[:, :-1].values,\n",
    "        df.iloc[:, -1].values,\n",
    "        test_size=0.2)\n",
    "    # 特征缩放\n",
    "    st_patterns = StandardScaler()\n",
    "    patterns_train = st_patterns.fit_transform(patterns_train)\n",
    "    patterns_valid = st_patterns.transform(patterns_valid)\n",
    "    # 数据类型转换\n",
    "    patterns_train = torch.Tensor(patterns_train)\n",
    "    patterns_valid = torch.Tensor(patterns_valid)\n",
    "    classes_train = torch.Tensor(classes_train)\n",
    "    classes_valid = torch.Tensor(classes_valid)\n",
    "    \n",
    "    return patterns_train, patterns_valid, classes_train, classes_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_prior(df_train: pd.DataFrame) -> torch.Tensor:\n",
    "    \"\"\"先验概率\n",
    "\n",
    "    Args:\n",
    "        df_train (pd.DataFrame)\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: P_prior\n",
    "    \"\"\"\n",
    "    \n",
    "    series = df_train[df_train.columns[-1]].value_counts(normalize=True)\n",
    "    P_prior = torch.Tensor([series.values[i] for i in range(series.size)])\n",
    "\n",
    "    return P_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_func(X: torch.Tensor, Y: torch.Tensor, h: float,\n",
    "                kernel: str) -> torch.Tensor:\n",
    "    \"\"\"核函数\n",
    "\n",
    "    Args:\n",
    "        X (torch.Tensor)\n",
    "        Y (torch.Tensor)\n",
    "        h (float): 核函数带宽\n",
    "        kernel (str): 核函数类型, 包括 'gaussian', 'epanechnikov', 'uniform' 三种\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Invalid kernel type\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor\n",
    "    \"\"\"\n",
    "\n",
    "    distance = torch.abs(X - Y)\n",
    "    if kernel == 'gaussian':\n",
    "        return torch.exp(-distance**2 / (2 * h**2))\n",
    "    # elif kernel == 'epanechnikov':\n",
    "    #     return 3 / 4 * (1 - distance**2 / h**2) if distance <= h else 0\n",
    "    # elif kernel == 'uniform':\n",
    "    #     return 1 / (2 * h) if distance <= h else 0\n",
    "    else:\n",
    "        raise ValueError('Invalid kernel type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_density_train(patterns: torch.Tensor, h: float,\n",
    "                 kernel: str) -> torch.Tensor:\n",
    "    \"\"\"训练集概率密度\n",
    "\n",
    "    Args:\n",
    "        patterns (torch.Tensor)\n",
    "        h (float): 核函数带宽\n",
    "        kernel (str): 核函数类型, 包括 'gaussian', 'epanechnikov', 'uniform' 三种\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: p_train\n",
    "    \"\"\"\n",
    "    # 核密度估计\n",
    "    p_train = kernel_func(patterns[:, None, :].T, patterns.T[..., None], h,\n",
    "                          kernel).sum(dim=1) / patterns.shape[0]\n",
    "    # 朴素贝叶斯方法\n",
    "    p_train = p_train.prod(dim=0)\n",
    "\n",
    "    return p_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_density_test(patterns_test: torch.Tensor,\n",
    "                      patterns_train: torch.Tensor,\n",
    "                      p_density_train: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"测试集概率密度\n",
    "\n",
    "    Args:\n",
    "        patterns_test (torch.Tensor)\n",
    "        patterns_train (torch.Tensor)\n",
    "        p_density_train (torch.Tensor)\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: p_test\n",
    "    \"\"\"\n",
    "\n",
    "    # 点积相似性\n",
    "    comparability = torch.mm(patterns_test, patterns_train.T) / torch.pow(\n",
    "        patterns_train.T, 2).sum(dim=0)[None, :]\n",
    "    # 最大相似性概率\n",
    "    max_ratios, max_indices = torch.max(comparability, dim=1)\n",
    "    p_test = p_density_train[max_indices] * max_ratios\n",
    "\n",
    "    return p_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_density_train(patterns_train: torch.Tensor, list_patterns_class: list,\n",
    "               h: float, kernel: str) -> tuple:\n",
    "    p_sample_train = p_density_train(patterns_train, h, kernel)\n",
    "    list_p_class_train = [\n",
    "        p_density_train(list_patterns_class[i], h, kernel)\n",
    "        for i in range(len(list_patterns_class))\n",
    "    ]\n",
    "\n",
    "    return p_sample_train, list_p_class_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_density_test(patterns_test: torch.Tensor,\n",
    "                      patterns_train: torch.Tensor, list_patterns_class: list,\n",
    "                      p_sample_train: torch.Tensor,\n",
    "                      list_p_class_train: list) -> tuple:\n",
    "\n",
    "    p_sample_test = p_density_test(patterns_test, patterns_train,\n",
    "                                   p_sample_train)\n",
    "    p_class_test = p_density_test(patterns_test, list_patterns_class[0],\n",
    "                                  list_p_class_train[0])\n",
    "    for i in range(len(list_patterns_class) - 1):\n",
    "        p_class_test = torch.cat([\n",
    "            p_class_test[:, None],\n",
    "            p_density_test(patterns_test, list_patterns_class[i + 1],\n",
    "                           list_p_class_train[i + 1])[:, None]\n",
    "        ],\n",
    "                                 dim=1)\n",
    "\n",
    "    return p_sample_test, p_class_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_posterior(patterns_train: torch.Tensor, patterns_test: torch.Tensor,\n",
    "                   classes_train: torch.Tensor, h: float,\n",
    "                   kernel: str) -> torch.Tensor:\n",
    "\n",
    "    df_train = pd.DataFrame(\n",
    "        torch.cat([patterns_train, classes_train[:, None]],\n",
    "                  dim=1).detach().numpy())\n",
    "    series = df_train[df_train.columns[-1]].value_counts()\n",
    "    list_patterns_class = [\n",
    "        torch.Tensor(df_train.loc[df_train[df_train.columns[-1]] ==\n",
    "                                  series.index[i]].iloc[:, :-1].values)\n",
    "        for i in range(series.size)\n",
    "    ]\n",
    "\n",
    "    P_prior = prob_prior(df_train)\n",
    "    p_sample_train, list_p_class_train = prob_density_train(\n",
    "        patterns_train, list_patterns_class, h, kernel)\n",
    "    p_sample_test, p_class_test = prob_density_test(patterns_test,\n",
    "                                                    patterns_train,\n",
    "                                                    list_patterns_class,\n",
    "                                                    p_sample_train,\n",
    "                                                    list_p_class_train)\n",
    "\n",
    "    P_prior = P_prior[None, :]\n",
    "    p_sample_test = p_sample_test[:, None]\n",
    "    P_posterior = torch.Tensor(P_prior * p_class_test / p_sample_test)\n",
    "    P_posterior = torch.divide(P_posterior, P_posterior.sum(dim=1)[:, None])\n",
    "\n",
    "    return P_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(patterns_train: torch.Tensor, patterns_test: torch.Tensor,\n",
    "          classes_train: torch.Tensor, h: float, kernel: str) -> torch.Tensor:\n",
    "\n",
    "    P_posterior = prob_posterior(patterns_train, patterns_test,\n",
    "                                      classes_train, h, kernel)\n",
    "\n",
    "    prob_classes, results_classes = torch.max(P_posterior, dim=1)\n",
    "\n",
    "    return prob_classes, results_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_classifier(df: pd.DataFrame,\n",
    "                        h: torch.Tensor,\n",
    "                        kernel: str = 'gaussian',\n",
    "                        mode: str = 'train',\n",
    "                        num_epochs: int = 10,\n",
    "                        num_search: int = 10,\n",
    "                        step_search: int = 0.015,\n",
    "                        patterns_test: torch.Tensor = None) -> torch.Tensor:\n",
    "    # 训练\n",
    "    if mode == 'train':\n",
    "        # 暴力搜索优化参数\n",
    "        accr = []\n",
    "        for i in range(num_search):\n",
    "            for _ in range(num_epochs):\n",
    "                patterns_train, patterns_valid, classes_train, classes_valid = data_pre_processing(\n",
    "                    df)\n",
    "                accr.append(\n",
    "                    accuracy_score(\n",
    "                        classes_valid,\n",
    "                        model(patterns_train, patterns_valid, classes_train,\n",
    "                              h + step_search * i, kernel)[1]))\n",
    "        accr = torch.tensor(accr, dtype=torch.float32).reshape(num_search, -1)\n",
    "        accuracy, index = accr.sum(dim=1).divide(num_epochs).max(dim=0)\n",
    "        h += index * step_search\n",
    "        return accuracy, h\n",
    "    # 预测\n",
    "    elif mode == 'eval':\n",
    "        if type(patterns_test) != torch.Tensor:\n",
    "            raise TypeError(\n",
    "                f'\\'patterns_test\\' must be a torch.Tensor but not be {type(patterns_test)}, when \\'mode\\' is \\'eval\\''\n",
    "            )\n",
    "        else:\n",
    "            if (len(patterns_test.shape) == 1) & (patterns_test.shape[0] != df.columns.size - 1):\n",
    "                raise ValueError(\n",
    "                    f'\\'patterns_test.shape[0]\\' must be equivalent to number of patterns in \\'df\\''\n",
    "                )\n",
    "            elif (len(patterns_test.shape) == 2) & (patterns_test.shape[1] != df.columns.size - 1):\n",
    "                raise ValueError(\n",
    "                    f'\\'patterns_test.shape[1]\\' must be equivalent to number of patterns in \\'df\\''\n",
    "                )\n",
    "            else:\n",
    "                patterns_train, patterns_valid, classes_train, classes_valid = data_pre_processing(\n",
    "                    df)\n",
    "                results, probabilities = model(patterns_train, patterns_test,\n",
    "                                             classes_train, h, kernel)\n",
    "                return results, probabilities\n",
    "    # 类型非法\n",
    "    else:\n",
    "        raise ValueError('Invalid mode type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据加载\n",
    "data_file = os.path.join('..', 'data', 'data_salmonbass.xlsx')\n",
    "data_raw = pd.read_excel(data_file)\n",
    "data_raw;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1000)\n"
     ]
    }
   ],
   "source": [
    "# 初始化模型参数\n",
    "# h = torch.normal(0, 0.1, size=(1, 1), requires_grad=True).squeeze(0)\n",
    "h = torch.tensor(0.1, dtype=torch.float32)\n",
    "h;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9296), tensor(0.1150))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练\n",
    "accuracy, h = bayesian_classifier(data_raw, h)\n",
    "accuracy, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.5808, 0.5835, 0.5839, 0.5856, 0.5929, 0.5887, 0.5863, 0.5831, 0.5866,\n",
       "         0.5885]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 预测\n",
    "results, probabilities = bayesian_classifier(\n",
    "    data_raw,\n",
    "    h,\n",
    "    mode='eval',\n",
    "    patterns_test=torch.Tensor(data_raw.head(10).iloc[:, :-1].values))\n",
    "results, probabilities"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8c8ecebabf5914b3a495bdc4ac6bae9931583c48dc0f9db7c8126a5c781d5a0e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.16 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

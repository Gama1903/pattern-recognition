{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from d2l import torch as d2l\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "data_file = os.path.join('..', 'data', 'data_salmonbass.xlsx')\n",
    "data_raw = pd.read_excel(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据处理\n",
    "\n",
    "# 独热编码\n",
    "# type_mapping = {type: idx for idx, type in enumerate(set(data_raw['type']))}\n",
    "# data_raw['type'] = data_raw['type'].map(type_mapping)\n",
    "data_raw = pd.get_dummies(data_raw)\n",
    "# 特征矩阵和标签\n",
    "inputs, outputs = data_raw.iloc[:, 0:2], data_raw.iloc[:, 2:4]\n",
    "features, labels = torch.Tensor(inputs.values), torch.Tensor(outputs.values)\n",
    "\n",
    "data_raw, inputs, outputs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络模型\n",
    "net = nn.Sequential(nn.Linear(2, 128), nn.ReLU(), nn.Linear(128, 64),\n",
    "                    nn.ReLU(), nn.Linear(64, 32), nn.ReLU(), nn.Linear(32, 16),\n",
    "                    nn.ReLU(), nn.Linear(16, 2))\n",
    "\n",
    "\n",
    "# 初始化权重\n",
    "def init_weight(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, std=0.01)\n",
    "\n",
    "\n",
    "net.apply(init_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "loss = nn.CrossEntropyLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 优化算法\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfolder(features, labels, k_fold=2):\n",
    "    \"\"\"k折交叉验证\"\"\"\n",
    "    for _ in range(k_fold):\n",
    "        train_x, test_x, train_y, test_y = train_test_split(features,\n",
    "                                                            labels,\n",
    "                                                            test_size=1 /\n",
    "                                                            k_fold)\n",
    "        train_x = torch.Tensor(train_x)\n",
    "        train_y = torch.Tensor(train_y)\n",
    "        test_x = torch.Tensor(test_x)\n",
    "        test_y = torch.Tensor(test_y)\n",
    "        yield (train_x, train_y), (test_x, test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iter(data_arrays, batch_size, is_train=True):\n",
    "    \"\"\"PyTorch数据迭代器\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, loss, num_epochs, updater):\n",
    "\n",
    "    animator = d2l.Animator(xlabel='epoch',\n",
    "                            xlim=[1, num_epochs],\n",
    "                            ylim=[0.3, 0.9],\n",
    "                            legend=['train loss', 'train acc', 'test acc'])\n",
    "    for epoch in range(num_epochs):\n",
    "        train_metrics = train_epoch(net, train_iter, loss, updater)\n",
    "        test_acc = d2l.evaluate_accuracy(net, test_iter)\n",
    "        animator.add(epoch + 1, train_metrics + (test_acc, ))\n",
    "    train_loss, train_acc = train_metrics\n",
    "    assert train_loss < 0.5, train_loss\n",
    "    assert train_acc <= 1 and train_acc > 0.7, train_acc\n",
    "    assert test_acc <= 1 and test_acc > 0.7, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(net, train_iter, loss, updater):\n",
    "\n",
    "    # Set the model to training mode\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.train()\n",
    "    # Sum of training loss, sum of training accuracy, no. of examples\n",
    "    metric = d2l.Accumulator(3)\n",
    "    for X, y in train_iter:\n",
    "        # Compute gradients and update parameters\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y)\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            # Using PyTorch in-built optimizer & loss criterion\n",
    "            updater.zero_grad()\n",
    "            l.mean().backward()\n",
    "            updater.step()\n",
    "        else:\n",
    "            # Using custom built optimizer & loss criterion\n",
    "            l.sum().backward()\n",
    "            updater(X.shape[0])\n",
    "        metric.add(float(l.sum()), accuracy(y_hat, y), y.numel())\n",
    "    # Return training loss and training accuracy\n",
    "    return metric[0] / metric[2], metric[1] / metric[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):\n",
    "\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = d2l.argmax(y_hat, axis=1)\n",
    "    cmp = d2l.astype(y_hat, y.dtype) == y\n",
    "    return float(d2l.reduce_sum(d2l.astype(cmp, y.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练（未实现）\n",
    "k = 10\n",
    "num_epochs = 10\n",
    "batch_size = 10\n",
    "for trainset, testset in kfolder(features, labels, k_fold=k):\n",
    "    train_iter = data_iter(trainset, batch_size)\n",
    "    test_iter = data_iter(testset, batch_size)\n",
    "    train(net, train_iter, test_iter, loss, num_epochs, trainer)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8c8ecebabf5914b3a495bdc4ac6bae9931583c48dc0f9db7c8126a5c781d5a0e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.16 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
